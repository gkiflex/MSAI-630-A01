{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnvqx7ImlnbKwOgD7iDmGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkiflex/MSAI-630-A01/blob/master/GptWineReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Wine Review Generator - Google Colab Version\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, callbacks\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 80\n",
        "EMBEDDING_DIM = 256\n",
        "KEY_DIM = 256\n",
        "N_HEADS = 2\n",
        "FEED_FORWARD_DIM = 256\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load dataset from sample_data folder\n",
        "df = pd.read_csv('/content/winemag-data-130k-v2.csv')\n",
        "print(f\"Dataset loaded: {df.shape}\")\n",
        "\n",
        "# Convert to wine data format\n",
        "wine_data = []\n",
        "for _, row in df.iterrows():\n",
        "    wine_data.append({\n",
        "        'country': row.get('country'),\n",
        "        'province': row.get('province'),\n",
        "        'variety': row.get('variety'),\n",
        "        'description': row.get('description')\n",
        "    })\n",
        "\n",
        "print(f\"Sample wine review:\\n{wine_data[10]}\")\n",
        "\n",
        "# Filter and format dataset\n",
        "filtered_data = [\n",
        "    \"wine review : \"\n",
        "    + str(x[\"country\"])\n",
        "    + \" : \"\n",
        "    + str(x[\"province\"])\n",
        "    + \" : \"\n",
        "    + str(x[\"variety\"])\n",
        "    + \" : \"\n",
        "    + str(x[\"description\"])\n",
        "    for x in wine_data\n",
        "    if x[\"country\"] is not None\n",
        "    and x[\"province\"] is not None\n",
        "    and x[\"variety\"] is not None\n",
        "    and x[\"description\"] is not None\n",
        "]\n",
        "\n",
        "n_wines = len(filtered_data)\n",
        "print(f\"{n_wines} wine reviews processed\")\n",
        "\n",
        "# Tokenization - pad punctuation\n",
        "def pad_punctuation(s):\n",
        "    s = re.sub(f\"([{string.punctuation}, '\\\\n'])\", r\" \\\\1 \", s)\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in filtered_data]\n",
        "\n",
        "# Create TensorFlow dataset\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")\n",
        "\n",
        "# Create vectorization layer\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "\n",
        "print(\"Vocabulary size:\", len(vocab))\n",
        "\n",
        "# Prepare training data\n",
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)\n",
        "\n",
        "# Causal attention mask\n",
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "# Transformer Block\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.attn = layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)\n",
        "        self.dropout_1 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.ffn_1 = layers.Dense(self.ff_dim, activation=\"relu\")\n",
        "        self.ffn_2 = layers.Dense(self.embed_dim)\n",
        "        self.dropout_2 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        attention_output, attention_scores = self.attn(\n",
        "            inputs, inputs, attention_mask=causal_mask, return_attention_scores=True\n",
        "        )\n",
        "        attention_output = self.dropout_1(attention_output)\n",
        "        out1 = self.ln_1(inputs + attention_output)\n",
        "        ffn_1 = self.ffn_1(out1)\n",
        "        ffn_2 = self.ffn_2(ffn_1)\n",
        "        ffn_output = self.dropout_2(ffn_2)\n",
        "        return (self.ln_2(out1 + ffn_output), attention_scores)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"key_dim\": self.key_dim,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"ff_dim\": self.ff_dim,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# Token and Position Embedding\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.max_len = max_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"max_len\": self.max_len,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# Build GPT model\n",
        "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "gpt = models.Model(inputs=inputs, outputs=[outputs, attention_scores])\n",
        "gpt.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])\n",
        "\n",
        "print(\"GPT Model created successfully!\")\n",
        "gpt.summary()\n",
        "\n",
        "# Text Generator\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.word_to_index = {word: index for index, word in enumerate(index_to_word)}\n",
        "\n",
        "    def sample_from(self, probs, temperature):\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [self.word_to_index.get(x, 1) for x in start_prompt.split()]\n",
        "        sample_token = None\n",
        "        info = []\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
        "            x = np.array([start_tokens])\n",
        "            y, att = self.model.predict(x, verbose=0)\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
        "            info.append({\n",
        "                \"prompt\": start_prompt,\n",
        "                \"word_probs\": probs,\n",
        "                \"atts\": att[0, :, -1, :],\n",
        "            })\n",
        "            start_tokens.append(sample_token)\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "        print(f\"\\\\nGenerated text (temperature={temperature}):\\\\n{start_prompt}\\\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.generate(\"wine review\", max_tokens=60, temperature=1.0)\n",
        "\n",
        "# Training callbacks\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "text_generator = TextGenerator(vocab)\n",
        "\n",
        "# Train model\n",
        "print(\"Starting training...\")\n",
        "history = gpt.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[model_checkpoint_callback, text_generator],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Generate with different temperatures\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATION WITH DIFFERENT TEMPERATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "temperatures = [0.2, 0.5, 0.8, 1.0, 1.2]\n",
        "prompts = [\"wine review : us\", \"wine review : italy\", \"wine review : france\"]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\\\n{'='*20} TEMPERATURE {temp} {'='*20}\")\n",
        "    results[temp] = {}\n",
        "\n",
        "    for prompt in prompts:\n",
        "        print(f\"\\\\nPrompt: '{prompt}'\")\n",
        "        info = text_generator.generate(prompt, max_tokens=60, temperature=temp)\n",
        "        results[temp][prompt] = info[-1]['prompt'] if info else \"No generation\"\n",
        "\n",
        "# Analysis output\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\"TEMPERATURE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"\\\\nPROMPT: {prompt}\")\n",
        "    print(\"-\" * 40)\n",
        "    for temp in temperatures:\n",
        "        generated_text = results[temp].get(prompt, \"No generation\")\n",
        "        display_text = generated_text[:100] + \"...\" if len(generated_text) > 100 else generated_text\n",
        "        print(f\"T={temp}: {display_text}\")\n",
        "\n",
        "# Save model\n",
        "gpt.save(\"gpt_wine_model.keras\")\n",
        "print(\"\\\\nğŸ· Model saved as 'gpt_wine_model.keras'\")\n",
        "print(\"Training and analysis complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WprYkMRQ4Xzg",
        "outputId": "a58df698-aec6-4ee0-c8c7-8c9b2630da82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Dataset loaded: (129971, 14)\n",
            "Sample wine review:\n",
            "{'country': 'US', 'province': 'California', 'variety': 'Cabernet Sauvignon', 'description': 'Soft, supple plum envelopes an oaky structure in this Cabernet, supported by 15% Merlot. Coffee and chocolate complete the picture, finishing strong at the end, resulting in a value-priced wine of attractive flavor and immediate accessibility.'}\n",
            "129971 wine reviews processed\n",
            "Vocabulary size: 10000\n",
            "GPT Model created successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_and_position_embedding_3  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â”‚     \u001b[38;5;34m2,580,480\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_3             â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    â”‚       \u001b[38;5;34m658,688\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTransformerBlock\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)    â”‚     \u001b[38;5;34m2,570,000\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_and_position_embedding_3  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,480</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_3             â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">658,688</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,809,168\u001b[0m (22.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,809,168</span> (22.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,809,168\u001b[0m (22.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,809,168</span> (22.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/5\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.1564\\nGenerated text (temperature=1.0):\\nwine review \\1 romania \\1 \\1 \\1 \\1 \\1 \\1 m \\1 \\1 grenache \\1 \\1 \\1 \\1 \\1 \\1 \\1 \\1 aged \\1 in \\1 both \\1 the \\1 dominant \\1 bottle \\1 \\1 30 \\1 \\1 \\1 \\1 \\1 \\1 \\1 \\1 \\1 and \\1 chardonnay \\1 5 \\1 \\1 bourboulenc \\1 with \\1 10 \\1 \\1 cabernet\\n\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 39ms/step - loss: 2.1563\n",
            "Epoch 2/5\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4884\\nGenerated text (temperature=1.0):\\nwine review \\1 \\1 \\1 \\1 chile \\1 \\1 \\1 colchagua \\1 valley \\1 \\1 \\1 red \\1 blend \\1 \\1 \\1 aromas \\1 of \\1 vanilla \\1 \\1 wood \\1 grain \\1 and \\1 violet \\1 lead \\1 to \\1 a \\1 fresh \\1 palate \\1 with \\1 red \\1 plum \\1 \\1 berry \\1 and \\1 cassis \\1\\n\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 27ms/step - loss: 1.4884\n",
            "Epoch 3/5\n",
            "\u001b[1m4061/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4156\\nGenerated text (temperature=1.0):\\nwine review \\1 \\1 \\1 \\1 portugal \\1 \\1 \\1 douro \\1 \\1 \\1 rosÃ© \\1 \\1 \\1 a \\1 blending \\1 grapes \\1 from \\1 landmark \\1 s \\1 estate \\1 to \\1 the \\1 18th \\1 century \\1 tower \\1 of \\1 the \\1 douro \\1 estate \\1 \\1 it \\1 is \\1 firm \\1 \\1 this \\1\\n\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 27ms/step - loss: 1.4156\n",
            "Epoch 4/5\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3753\\nGenerated text (temperature=1.0):\\nwine review \\1 \\1 \\1 \\1 come \\1 \\1 \\1 predominantly \\1 \\1 \\1 sangiovese \\1 \\1 \\1 a \\1 tad \\1 simple \\1 in \\1 bottle \\1 \\1 with \\1 asphalt \\1 [UNK] \\1 aromas \\1 of \\1 graphite \\1 \\1 tar \\1 \\1 charred \\1 earth \\1 and \\1 leather \\1 \\1 cigar \\1 box \\1 on \\1\\n\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 27ms/step - loss: 1.3753\n",
            "Epoch 5/5\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3472\\nGenerated text (temperature=1.0):\\nwine review review \\1 \\1 \\1 us \\1 \\1 \\1 oregon \\1 \\1 \\1 red \\1 blend \\1 \\1 \\1 this \\1 40 \\1 \\1 merlot \\1 has \\1 a \\1 problematic \\1 wine \\1 that \\1 was \\1 just \\1 picked \\1 brought \\1 out \\1 well \\1 into \\1 a \\1 rich \\1 \\1 powerful \\1 fruit \\1\\n\n",
            "\u001b[1m4062/4062\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 27ms/step - loss: 1.3472\n",
            "Training completed!\n",
            "============================================================\n",
            "GENERATION WITH DIFFERENT TEMPERATURES\n",
            "============================================================\n",
            "\\n==================== TEMPERATURE 0.2 ====================\n",
            "\\nPrompt: 'wine review : us'\n",
            "\\nGenerated text (temperature=0.2):\\nwine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 pinot \\1 noir \\1 \\1 \\1 a \\1 big \\1 \\1 rich \\1 \\1 extracted \\1 pinot \\1 noir \\1 \\1 with \\1 a \\1 silky \\1 mouthfeel \\1 \\1 it \\1 s \\1 a \\1 little \\1 too \\1 sweet \\1 \\1 with \\1 flavors\\n\n",
            "\\nPrompt: 'wine review : italy'\n",
            "\\nGenerated text (temperature=0.2):\\nwine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 pinot \\1 noir \\1 \\1 \\1 a \\1 big \\1 \\1 rich \\1 \\1 full \\1 bodied \\1 wine \\1 \\1 with \\1 a \\1 wealth \\1 of \\1 cherry \\1 and \\1 raspberry \\1 flavors \\1 \\1 it \\1 s \\1 dry \\1 \\1 with\\n\n",
            "\\nPrompt: 'wine review : france'\n",
            "\\nGenerated text (temperature=0.2):\\nwine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 this \\1 is \\1 a \\1 rich \\1 \\1 rich \\1 chardonnay \\1 \\1 with \\1 a \\1 rich \\1 \\1 creamy \\1 texture \\1 and \\1 a \\1 little \\1 sweet \\1 \\1 it \\1 s \\1 a \\1 little \\1\\n\n",
            "\\n==================== TEMPERATURE 0.5 ====================\n",
            "\\nPrompt: 'wine review : us'\n",
            "\\nGenerated text (temperature=0.5):\\nwine review : us \\1 \\1 us \\1 \\1 \\1 washington \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 this \\1 wine \\1 is \\1 a \\1 blend \\1 of \\1 fruit \\1 from \\1 the \\1 winery \\1 s \\1 estate \\1 grown \\1 in \\1 the \\1 eola \\1 amity \\1 hills \\1 ava \\1 \\1 it\\n\n",
            "\\nPrompt: 'wine review : italy'\n",
            "\\nGenerated text (temperature=0.5):\\nwine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 the \\1 winery \\1 calls \\1 this \\1 out \\1 a \\1 dessert \\1 wine \\1 \\1 it \\1 s \\1 dry \\1 and \\1 crisp \\1 in \\1 acidity \\1 \\1 it \\1 s \\1 a \\1 little \\1 too \\1\\n\n",
            "\\nPrompt: 'wine review : france'\n",
            "\\nGenerated text (temperature=0.5):\\nwine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 the \\1 [UNK] \\1 [UNK] \\1 [UNK] \\1 s \\1 2008 \\1 [UNK] \\1 \\1 the \\1 [UNK] \\1 is \\1 a \\1 big \\1 \\1 chewy \\1 wine \\1 \\1 with \\1 black \\1 cherry \\1 and \\1 chocolate\\n\n",
            "\\n==================== TEMPERATURE 0.8 ====================\n",
            "\\nPrompt: 'wine review : us'\n",
            "\\nGenerated text (temperature=0.8):\\nwine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 [UNK] \\1 is \\1 the \\1 most \\1 successful \\1 of \\1 the \\1 winery \\1 s \\1 2007 \\1 2012 \\1 vintage \\1 \\1 the \\1 wine \\1 is \\1 stainless \\1 steel \\1 barrels \\1 \\1 large \\1 production \\1\\n\n",
            "\\nPrompt: 'wine review : italy'\n",
            "\\nGenerated text (temperature=0.8):\\nwine review : italy \\1 \\1 portugal \\1 \\1 \\1 vinho \\1 verde \\1 \\1 \\1 portuguese \\1 white \\1 \\1 \\1 this \\1 is \\1 a \\1 soft \\1 \\1 creamy \\1 wine \\1 \\1 with \\1 great \\1 acidity \\1 that \\1 is \\1 ready \\1 to \\1 drink \\1 \\1 its \\1 light \\1 apricot \\1 flavors\\n\n",
            "\\nPrompt: 'wine review : france'\n",
            "\\nGenerated text (temperature=0.8):\\nwine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 rhÃ´ne \\1 style \\1 red \\1 blend \\1 \\1 \\1 made \\1 in \\1 a \\1 blend \\1 of \\1 grenache \\1 \\1 mourvÃ¨dre \\1 \\1 petite \\1 sirah \\1 and \\1 mourvÃ¨dre \\1 \\1 this \\1 bottling \\1 is \\1 nearly \\1 equal \\1 mourvÃ¨dre\\n\n",
            "\\n==================== TEMPERATURE 1.0 ====================\n",
            "\\nPrompt: 'wine review : us'\n",
            "\\nGenerated text (temperature=1.0):\\nwine review : us \\1 \\1 austria \\1 \\1 \\1 kremstal \\1 \\1 \\1 grÃ¼ner \\1 veltliner \\1 \\1 \\1 sonorous \\1 \\1 bready \\1 notes \\1 of \\1 pear \\1 [UNK] \\1 the \\1 conference \\1 pear \\1 nose \\1 are \\1 smooth \\1 and \\1 creamy \\1 with \\1 little \\1 autolysis \\1 \\1 the \\1 palate \\1\\n\n",
            "\\nPrompt: 'wine review : italy'\n",
            "\\nGenerated text (temperature=1.0):\\nwine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 rosÃ© \\1 \\1 \\1 this \\1 is \\1 so \\1 very \\1 nice \\1 \\1 with \\1 pure \\1 red \\1 currant \\1 \\1 mocha \\1 and \\1 spice \\1 flavors \\1 that \\1 make \\1 it \\1 a \\1 good \\1 to \\1 drink \\1\\n\n",
            "\\nPrompt: 'wine review : france'\n",
            "\\nGenerated text (temperature=1.0):\\nwine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 sugary \\1 sweet \\1 and \\1 simple \\1 \\1 sweet \\1 and \\1 tart \\1 in \\1 blackberry \\1 and \\1 currant \\1 \\1 with \\1 sharp \\1 acidity \\1 \\1 thyme \\1 \\1 tobacco \\1 \\1 grilled \\1 beef\\n\n",
            "\\n==================== TEMPERATURE 1.2 ====================\n",
            "\\nPrompt: 'wine review : us'\n",
            "\\nGenerated text (temperature=1.2):\\nwine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 zinfandel \\1 \\1 \\1 deep \\1 aromas \\1 of \\1 black \\1 licorice \\1 and \\1 dried \\1 cheese \\1 lead \\1 to \\1 rooty \\1 lavish \\1 fruit \\1 before \\1 unveiling \\1 waves \\1 of \\1 dried \\1 figs \\1 as \\1 as \\1\\n\n",
            "\\nPrompt: 'wine review : italy'\n",
            "\\nGenerated text (temperature=1.2):\\nwine review : italy \\1 \\1 france \\1 in \\1 malvasia \\1 de \\1 setÃºbal \\1 \\1 \\1 white \\1 blend \\1 \\1 \\1 the \\1 accents \\1 of \\1 softer \\1 and \\1 expressing \\1 superripe \\1 aspect \\1 eiswein \\1 and \\1 much \\1 nevertheless \\1 without \\1 power \\1 \\1 the \\1 palate \\1 \\1 the \\1\\n\n",
            "\\nPrompt: 'wine review : france'\n",
            "\\nGenerated text (temperature=1.2):\\nwine review : france \\1 \\1 italy \\1 \\1 and \\1 \\1 france \\1 \\1 \\1 burgundy \\1 here \\1 rich \\1 wine \\1 \\1 with \\1 flavors \\1 of \\1 soapy \\1 smoothness \\1 \\1 it \\1 shows \\1 ample \\1 structure \\1 in \\1 the \\1 mouth \\1 yet \\1 imparts \\1 bitter \\1 flavors \\1 of \\1\\n\n",
            "\\n================================================================================\n",
            "TEMPERATURE ANALYSIS\n",
            "================================================================================\n",
            "\\nPROMPT: wine review : us\n",
            "----------------------------------------\n",
            "T=0.2: wine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 pinot \\1 noir \\1 \\1 \\1 a \\1 big \\1 \\1 rich \\1...\n",
            "T=0.5: wine review : us \\1 \\1 us \\1 \\1 \\1 washington \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 this \\1 wine \\...\n",
            "T=0.8: wine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 [UNK] \\1 is \\1 the \\1 mos...\n",
            "T=1.0: wine review : us \\1 \\1 austria \\1 \\1 \\1 kremstal \\1 \\1 \\1 grÃ¼ner \\1 veltliner \\1 \\1 \\1 sonorous \\1 \\...\n",
            "T=1.2: wine review : us \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 zinfandel \\1 \\1 \\1 deep \\1 aromas \\1 of \\1 bl...\n",
            "\\nPROMPT: wine review : italy\n",
            "----------------------------------------\n",
            "T=0.2: wine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 pinot \\1 noir \\1 \\1 \\1 a \\1 big \\1 \\1 rich...\n",
            "T=0.5: wine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 the \\1 winery \\1 calls...\n",
            "T=0.8: wine review : italy \\1 \\1 portugal \\1 \\1 \\1 vinho \\1 verde \\1 \\1 \\1 portuguese \\1 white \\1 \\1 \\1 thi...\n",
            "T=1.0: wine review : italy \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 rosÃ© \\1 \\1 \\1 this \\1 is \\1 so \\1 very \\1 ...\n",
            "T=1.2: wine review : italy \\1 \\1 france \\1 in \\1 malvasia \\1 de \\1 setÃºbal \\1 \\1 \\1 white \\1 blend \\1 \\1 \\1...\n",
            "\\nPROMPT: wine review : france\n",
            "----------------------------------------\n",
            "T=0.2: wine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 chardonnay \\1 \\1 \\1 this \\1 is \\1 a \\1 ri...\n",
            "T=0.5: wine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 the \\1 [UN...\n",
            "T=0.8: wine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 rhÃ´ne \\1 style \\1 red \\1 blend \\1 \\1 \\1 m...\n",
            "T=1.0: wine review : france \\1 \\1 us \\1 \\1 \\1 california \\1 \\1 \\1 cabernet \\1 sauvignon \\1 \\1 \\1 sugary \\1 ...\n",
            "T=1.2: wine review : france \\1 \\1 italy \\1 \\1 and \\1 \\1 france \\1 \\1 \\1 burgundy \\1 here \\1 rich \\1 wine \\1...\n",
            "\\nğŸ· Model saved as 'gpt_wine_model.keras'\n",
            "Training and analysis complete!\n"
          ]
        }
      ]
    }
  ]
}